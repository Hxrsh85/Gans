{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim=10, im_chan=1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(input_dim, hidden_dim * 4),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim),\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        x = noise.view(len(noise), self.input_dim, 1, 1)\n",
    "        return self.gen(x)\n",
    "\n",
    "def combine_vectors(x, y):\n",
    "    return torch.cat((x.float(), y.float()), 1)\n",
    "\n",
    "def generate_single_image(generator, class_label, z_dim, n_classes):\n",
    "    noise = torch.randn(1, z_dim)\n",
    "    one_hot_label = torch.zeros(1, n_classes)\n",
    "    one_hot_label[0][class_label] = 1\n",
    "    noise_and_label = combine_vectors(noise, one_hot_label)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fake_image = generator(noise_and_label)\n",
    "\n",
    "    # Convert the generated image from a tensor to a numpy array for display\n",
    "    img = (fake_image.squeeze().numpy() + 1) / 2  # Normalize to [0, 1]\n",
    "    return img\n",
    "\n",
    "def display_image(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    z_dim = 64\n",
    "    n_classes = 10\n",
    "    epoch = input(\"Enter the epoch number you want to load (e.g., 1, 11, 21...): \")\n",
    "    class_label = int(input(f\"Enter the number you want to generate (0 to {n_classes - 1}): \"))\n",
    "\n",
    "    # Paths (modify these according to your folder structure)\n",
    "    checkpoint_dir = '/path_to_checkpoints_folder'  # Folder where the checkpoints are stored\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'generator_epoch_{epoch}.pth')\n",
    "\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        # Load the generator model for the specified epoch\n",
    "        generator = Generator(input_dim=z_dim + n_classes)\n",
    "        generator.load_state_dict(torch.load(checkpoint_path))\n",
    "        generator.eval()\n",
    "\n",
    "        # Generate the image for the specified class label\n",
    "        generated_image = generate_single_image(generator, class_label, z_dim, n_classes)\n",
    "\n",
    "        # Display the generated image in the notebook\n",
    "        display_image(generated_image)\n",
    "    else:\n",
    "        print(f\"Checkpoint {checkpoint_path} not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
